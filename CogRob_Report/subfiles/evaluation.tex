%!TEX root = ../report.tex
\documentclass[../report.tex]{subfiles}

% We need to mention the effects of having the memory observed from running from a blank-slate memory versus the second run with the memory of the first run

\begin{document}
\section{Evaluation}
\label{sec:evaluation}
To evaluate the agent's performance, multiple language models were tested on completing tasks within the environment. The evaluated models include OpenAI's GPT-4.1-mini, Anthropic's Claude 3.5 Sonnet, and Qwen's Qwen3 Coder 480B A35B Instruct. These models represent a small but diverse selection of leading language models from different providers, allowing for a comprehensive comparison of their capabilities in the robotic task completion domain. The tasks on which the agent was evaluated are described in the following sections.

\subsection{Task 1: Placing all Items into the Shelf}
The first task the agent had to perform within the simulated environment consists of placing all items, here a mug, a box and a cube, into the three-layered shelf. The agent needs to successfully navigate to each of the items, grab them, then navigate to the shelf and place them in an unoccupied layer.

During execution of this task, many models would take the task prompt "Please put all the objects away into the shelf" quite literally and attempt to move a TV object into the shelf. The design of the environment prevents this however, and agents would report failure when attempting to grab the TV. Despite this misinterpretation, the intended objects (the mug, box and cube) would indeed be correctly moved into the shelf by all models that were evaluated. This showed that while the agents were capable of performing the core task, they sometimes struggled with interpreting ambiguous instructions.

The agent (powered by each of the chosen models) hence performed this task successfully without running into larger failures. All models performed in a similar manner in this task.

\subsection{Task 2: Reordering the Items in the Shelf}
After completing the first task, the second task for the agent is to change the order of the items in the now fully occupied shelf. All items need to be placed on a different layer to the one they are currently placed on. To successfully complete this task, the agent needs to figure out that it cannot rearrange the items without storing one item in a location outside of the shelf. The prompt used for this task takes the form of: ``Please put the mug in the top of the shelf and cube in the middle. The box should be still in the shelf somewhere.'' Note that the object positions in the shelf would be changed so that the objects need to be moved after the resulting order of the first task.

The success of the agent is not as certain as the prior task. Many times the agent gets stuck in trying to place items into occupied locations but it can find a plan involving a temporary storage location, for example the kitchen table, after a while. After successfully utilizing a temporary storage location the agent successfully completes the task.

A significant improvement in performance was observed when comparing the agent's first attempt at this task versus subsequent attempts. During the initial run, the agent had no prior experience with the task and would often attempt to grab multiple objects simultaneously, leading to failures. However, these failure experiences were stored in the agent's episodic memory through the ChromaDB system. When the agent encountered the same or similar task in subsequent runs, it could query its memory for past experiences related to object manipulation and rearrangement. By retrieving memories of previous failures where it attempted to grab multiple objects at once, the agent learned to avoid this approach. Instead of going through the trial and error process of discovering that it cannot grab multiple objects simultaneously, the agent directly proceeded with using a temporary storage location strategy, having learned from its past experiences. This demonstrates the value of episodic memory in accelerating task completion by avoiding previously encountered pitfalls. The biggest issue with the task does not lie in its execution but in getting the agent to attempt the task in the first place. This is described in more detail in the next section.

\subsection{Interaction Problems with the Agent}
During prompting the agent with a new task, after it has successfully completed a task, it can happen that the model refuses to attempt the new task. It states that it already has completed the new task, as it assumes the new task is the same as the old task. Sometimes clarifying that the new task is indeed a new task works, but the agent can remain in this deadlock of refusing any new tasks. In addition, it may also be the case that the LLM agent ends its turn prematurely without using its tools to perform actions in the environment.

To mitigate this issue, a mechanism was implemented that repeatedly prompts the model with the current task until it explicitly requests task completion. This approach ensures that even if the model initially refuses to perform the new task, gets stuck in a deadlock, or ends the turn prematurely, it will be repeatedly prompted with the task until it either tries to complete it or explicitly acknowledges completion. The repeated invocation serves as a form of external pressure that helps overcome the agent's tendency to assume tasks are already completed, often breaking the deadlock state and ensuring task execution.

Further, it was observed during testing and evaluation that Anthropic's Claude 3.5 Sonnet exhibited significantly slower response times compared to the other models, with wall times of 30-40 seconds between consecutive tool calls. This performance issue heavily limited the evaluation of this model, as it drastically increased the time required to complete tasks and affected the overall user experience.

\subsection{Select Evaluation Videos}
\begin{itemize}
	\item \textbf{Reasoning Fail with Qwen3 Coder:} \\ \href{https://youtu.be/L8oyPOKOPFU}{\nolinkurl{https://youtu.be/L8oyPOKOPFU}}
	\item \textbf{Memory Helping Subsequent Executions with Qwen3 Coder:} \\ \href{https://www.youtube.com/watch?v=mSL3amblRxI}{\nolinkurl{https://www.youtube.com/watch?v=mSL3amblRxI}}
	\item \textbf{Simulation Error with Qwen3 Coder:} \\ \href{https://www.youtube.com/watch?v=MFkeDJnpZHw}{\nolinkurl{https://www.youtube.com/watch?v=MFkeDJnpZHw}}
	\item \textbf{GPT-4.1 Ignores Second Task:} \\ \href{https://www.youtube.com/watch?v=7TxQeGHyXgs}{\nolinkurl{https://www.youtube.com/watch?v=7TxQeGHyXgs}}
\end{itemize}


\end{document}
