%!TEX root = ../report.tex
\documentclass[../report.tex]{subfiles}

\begin{document}
\section{Introduction}
\label{sec:introduction}

Large Language Models (LLMs) have been shown to exhibit impressive abilities in reasoning, language understanding, and task execution. This project explores how an LLM can serve as the core of a cognitive architecture embodied in a simulated 3D robot. By assigning the agent physical tasks in a realistic environment, we aim to investigate how such systems can perceive, plan, act, and adapt in grounded, interactive settings.

\subsection{Motivation}
\label{sec:introduction:motivation}

To fully explore the cognitive capabilities of large language models, it is essential to situate them in environments that demand embodied, goal-directed interaction. This project investigates how LLMs function as the core of a cognitive architecture within a simulated 3D robotic setting, where the agent must physically manipulate objects and execute tasks in the real world.

Unlike static text-based benchmarks, a robotic context enables examination of embodied reasoning, memory-guided action, and the capacity for grounded, anticipatory planning. By focusing on a single agent operating in a realistic environment -- such as a kitchen -- we can probe how LLMs reason about spatial layouts, interpret user instructions, and adapt plans based on feedback.

Importantly, the robot's (and by extension, the LLM agent's) planning and decision-making capabilities take on a more grounded role, reasoning in natural language about the physical consequences of movements and manipulative actions. This opens new directions for exploring embodied cognition and could inform future developments in cognitive robotics, assistive AI, and multi-modal agent systems.

\subsection{Problem Statement}
\label{sec:introduction:problem_statement}

[ChatGPT draft]
While LLMs have shown remarkable performance in language-based reasoning and planning, their ability to operate as the cognitive core of embodied agents in interactive environments is not well understood. The central problem addressed in this project is how to enable an LLM-driven agent to perceive, plan, and act within a simulated household setting, where it must manipulate objects, navigate between rooms, and complete multi-step tasks. This requires bridging the gap between high-level natural language reasoning and low-level embodied interaction, while coping with the inherent challenges of memory, grounding, and decision consistency.

\subsection{Proposed Approach}
\label{sec:introduction:proposed_approach}

[Modified ChatGPT draft]
To address this problem, a cognitive robotic agent was designed that embeds an LLM as its central reasoning engine and situates it in a PyBullet simulation of a household environment. The agent is embodied as a mobile manipulator with a 7-DoF arm mounted on an omnidirectional base, enabling navigation and object manipulation. A set of high-level tool functions were implemented to expose perception, navigation, grasping, and placement as callable actions for the LLM. Object placement and shelf reordering were chosen to test the agentâ€™s ability to execute complex high level tasks, utilize episodic memory, and adapt to constraints such as occupied spaces. This work evaluates to wich extent LLMs can act as cognitive controllers for robots and identify their strengths and limitations in performing high level tasks.

\end{document}
